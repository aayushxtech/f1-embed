{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc24814-b11e-4f00-a1dd-982e0a786e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb019d73-39cd-4a81-abf6-1e9d9bde6f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_context = np.load(\"X_context.npy\")\n",
    "X_seq = np.load(\"X_seq.npy\")\n",
    "y = np.load(\"y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aff4e47c-fe93-404e-a897-702aded4f4f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.12370000e+04, 2.80000000e+02, 7.00000000e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 1.20000000e+01],\n",
       "        [9.97661504e+03, 2.45843996e+02, 6.91694725e+00, 0.00000000e+00,\n",
       "         1.00000000e+00, 8.00000000e+00],\n",
       "        [1.03103232e+04, 1.81702020e+02, 4.81313131e+00, 0.00000000e+00,\n",
       "         1.00000000e+00, 8.00000000e+00],\n",
       "        ...,\n",
       "        [1.12885047e+04, 2.43702886e+02, 6.00000000e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 1.20000000e+01],\n",
       "        [1.15466442e+04, 2.58750842e+02, 6.25028058e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 1.20000000e+01],\n",
       "        [1.09620000e+04, 2.73000000e+02, 7.00000000e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 1.20000000e+01]],\n",
       "\n",
       "       [[1.06870000e+04, 2.32000000e+02, 6.00000000e+00, 9.90000000e+01,\n",
       "         0.00000000e+00, 9.00000000e+00],\n",
       "        [1.13356593e+04, 2.48772854e+02, 6.00000000e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 9.00000000e+00],\n",
       "        [1.07333008e+04, 2.60033317e+02, 6.00832931e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 9.00000000e+00],\n",
       "        ...,\n",
       "        [9.84549601e+03, 1.83773434e+02, 5.00000000e+00, 6.54804545e+01,\n",
       "         0.00000000e+00, 9.00000000e+00],\n",
       "        [1.04735268e+04, 1.93479293e+02, 5.00000000e+00, 8.69447811e+01,\n",
       "         0.00000000e+00, 9.00000000e+00],\n",
       "        [1.13805375e+04, 2.12287500e+02, 5.00000000e+00, 9.93812500e+01,\n",
       "         0.00000000e+00, 9.00000000e+00]],\n",
       "\n",
       "       [[1.07770000e+04, 2.68000000e+02, 7.00000000e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 8.00000000e+00],\n",
       "        [1.11116394e+04, 2.77345174e+02, 7.00000000e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 8.00000000e+00],\n",
       "        [1.13361491e+04, 2.82129660e+02, 7.00000000e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 8.00000000e+00],\n",
       "        ...,\n",
       "        [1.16195120e+04, 2.55893434e+02, 6.00000000e+00, 9.90000000e+01,\n",
       "         0.00000000e+00, 1.00000000e+00],\n",
       "        [1.07262929e+04, 2.65946717e+02, 7.00000000e+00, 9.98422138e+01,\n",
       "         0.00000000e+00, 1.00000000e+00],\n",
       "        [1.10470000e+04, 2.75000000e+02, 7.00000000e+00, 9.90000000e+01,\n",
       "         0.00000000e+00, 1.00000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.10030000e+04, 2.78000000e+02, 7.00000000e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 1.20000000e+01],\n",
       "        [1.06219159e+04, 2.78363182e+02, 7.00000000e+00, 0.00000000e+00,\n",
       "         4.04090909e-01, 0.00000000e+00],\n",
       "        [9.61731777e+03, 2.12298554e+02, 7.00000000e+00, 0.00000000e+00,\n",
       "         1.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [1.10877114e+04, 2.42448864e+02, 6.00000000e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 1.20000000e+01],\n",
       "        [1.16416114e+04, 2.60979545e+02, 6.00000000e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 1.20000000e+01],\n",
       "        [1.09210000e+04, 2.74000000e+02, 7.00000000e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 1.20000000e+01]],\n",
       "\n",
       "       [[1.10530000e+04, 2.77000000e+02, 7.00000000e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 1.20000000e+01],\n",
       "        [1.10773960e+04, 2.82143434e+02, 7.00000000e+00, 5.32727273e+00,\n",
       "         4.08080808e-01, 0.00000000e+00],\n",
       "        [9.17431439e+03, 2.21291667e+02, 7.00000000e+00, 0.00000000e+00,\n",
       "         1.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [1.11008081e+04, 2.45919192e+02, 6.00000000e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 1.20000000e+01],\n",
       "        [1.10852071e+04, 2.60959596e+02, 6.49595960e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 1.20000000e+01],\n",
       "        [1.10660000e+04, 2.76000000e+02, 7.00000000e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 1.20000000e+01]],\n",
       "\n",
       "       [[1.10530000e+04, 2.78000000e+02, 7.00000000e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 1.20000000e+01],\n",
       "        [1.05303293e+04, 2.65569361e+02, 7.00000000e+00, 0.00000000e+00,\n",
       "         1.00000000e+00, 0.00000000e+00],\n",
       "        [9.71637374e+03, 2.22646465e+02, 7.00000000e+00, 0.00000000e+00,\n",
       "         1.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [1.09696368e+04, 2.43116947e+02, 6.00000000e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 1.20000000e+01],\n",
       "        [1.07155659e+04, 2.59410167e+02, 6.00000000e+00, 1.00000000e+02,\n",
       "         0.00000000e+00, 1.20000000e+01],\n",
       "        [1.05370000e+04, 2.69000000e+02, 7.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 8.00000000e+00]]], shape=(1770, 100, 6))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3030fa9-aecd-426d-8fc2-7325adabe364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32833267-0c42-4de9-bac3-d25d571b0645",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea7a5627-799a-4a70-9a4c-e9dd49ea9c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq_flat = X_seq.reshape(-1, X_seq.shape[-1])\n",
    "X_seq_scaled = scaler.fit_transform(X_seq_flat)\n",
    "X_seq = X_seq_scaled.reshape(X_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c47d957-5422-4d58-98bb-41481235e9d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.80653561,  1.16983974,  1.07150979,  0.88477417,\n",
       "         -0.53378254,  2.17124441],\n",
       "        [-0.01911465,  0.68856125,  1.02652099, -1.55249831,\n",
       "          2.02601213,  1.19631749],\n",
       "        [ 0.19949019, -0.21523745, -0.11309382, -1.55249831,\n",
       "          2.02601213,  1.19631749],\n",
       "        ...,\n",
       "        [ 0.84027517,  0.65839174,  0.52982038,  0.88477417,\n",
       "         -0.53378254,  2.17124441],\n",
       "        [ 1.00937668,  0.87042642,  0.66539472,  0.88477417,\n",
       "         -0.53378254,  2.17124441],\n",
       "        [ 0.6263892 ,  1.07120556,  1.07150979,  0.88477417,\n",
       "         -0.53378254,  2.17124441]],\n",
       "\n",
       "       [[ 0.4462428 ,  0.4934911 ,  0.52982038,  0.86040144,\n",
       "         -0.53378254,  1.44004922],\n",
       "        [ 0.87116513,  0.72983061,  0.52982038,  0.88477417,\n",
       "         -0.53378254,  1.44004922],\n",
       "        [ 0.47657344,  0.88849726,  0.53433227,  0.88477417,\n",
       "         -0.53378254,  1.44004922],\n",
       "        ...,\n",
       "        [-0.10500782, -0.18604999, -0.01186903,  0.04343879,\n",
       "         -0.53378254,  1.44004922],\n",
       "        [ 0.30640121, -0.04928865, -0.01186903,  0.56658291,\n",
       "         -0.53378254,  1.44004922],\n",
       "        [ 0.90056385,  0.21573021, -0.01186903,  0.86969354,\n",
       "         -0.53378254,  1.44004922]],\n",
       "\n",
       "       [[ 0.5051998 ,  1.00075258,  1.07150979,  0.88477417,\n",
       "         -0.53378254,  1.19631749],\n",
       "        [ 0.72441466,  1.13243166,  1.07150979,  0.88477417,\n",
       "         -0.53378254,  1.19631749],\n",
       "        [ 0.87148601,  1.19984792,  1.07150979,  0.88477417,\n",
       "         -0.53378254,  1.19631749],\n",
       "        ...,\n",
       "        [ 1.05711072,  0.83016384,  0.52982038,  0.86040144,\n",
       "         -0.53378254, -0.50980461],\n",
       "        [ 0.4719827 ,  0.9718206 ,  1.07150979,  0.88092849,\n",
       "         -0.53378254, -0.50980461],\n",
       "        [ 0.68207082,  1.09938676,  1.07150979,  0.86040144,\n",
       "         -0.53378254, -0.50980461]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.6532474 ,  1.14165855,  1.07150979,  0.88477417,\n",
       "         -0.53378254,  2.17124441],\n",
       "        [ 0.40360765,  1.14677599,  1.07150979, -1.55249831,\n",
       "          0.50060722, -0.75353634],\n",
       "        [-0.25448234,  0.21588596,  1.07150979, -1.55249831,\n",
       "          2.02601213, -0.75353634],\n",
       "        ...,\n",
       "        [ 0.70873993,  0.64072182,  0.52982038,  0.88477417,\n",
       "         -0.53378254,  2.17124441],\n",
       "        [ 1.07158755,  0.90183018,  0.52982038,  0.88477417,\n",
       "         -0.53378254,  2.17124441],\n",
       "        [ 0.59953101,  1.08529616,  1.07150979,  0.88477417,\n",
       "         -0.53378254,  2.17124441]],\n",
       "\n",
       "       [[ 0.68600129,  1.12756795,  1.07150979,  0.88477417,\n",
       "         -0.53378254,  2.17124441],\n",
       "        [ 0.70198254,  1.20004201,  1.07150979, -1.42265816,\n",
       "          0.51082054, -0.75353634],\n",
       "        [-0.54468403,  0.34260429,  1.07150979, -1.55249831,\n",
       "          2.02601213, -0.75353634],\n",
       "        ...,\n",
       "        [ 0.7173193 ,  0.68962082,  0.52982038,  0.88477417,\n",
       "         -0.53378254,  2.17124441],\n",
       "        [ 0.70709943,  0.90154908,  0.79847644,  0.88477417,\n",
       "         -0.53378254,  2.17124441],\n",
       "        [ 0.6945173 ,  1.11347735,  1.07150979,  0.88477417,\n",
       "         -0.53378254,  2.17124441]],\n",
       "\n",
       "       [[ 0.68600129,  1.14165855,  1.07150979,  0.88477417,\n",
       "         -0.53378254,  2.17124441],\n",
       "        [ 0.34361132,  0.96650343,  1.07150979, -1.55249831,\n",
       "          2.02601213, -0.75353634],\n",
       "        [-0.18959297,  0.3616942 ,  1.07150979, -1.55249831,\n",
       "          2.02601213, -0.75353634],\n",
       "        ...,\n",
       "        [ 0.63139187,  0.65013552,  0.52982038,  0.88477417,\n",
       "         -0.53378254,  2.17124441],\n",
       "        [ 0.46495571,  0.8797167 ,  0.52982038,  0.88477417,\n",
       "         -0.53378254,  2.17124441],\n",
       "        [ 0.34798112,  1.01484318,  1.07150979, -1.55249831,\n",
       "         -0.53378254,  1.19631749]]], shape=(1770, 100, 6))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c6cfc09-c22e-40c2-a88e-d6d4b6942fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.000e+00, 2.022e+03, 2.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "       0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "       0.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "       1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_context[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cebdd2e7-80cf-4ad7-a32a-2e9f76c8184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_normalize1 = X_context[:, 0].reshape(-1, 1)\n",
    "column_to_normalize2 = X_context[:, 1].reshape(-1, 1)\n",
    "column_to_normalize3 = X_context[:, 2].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59ae9e92-192d-43bf-8eab-2d30be23cba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_column1 = scaler.fit_transform(column_to_normalize1)\n",
    "standardized_column2 = scaler.fit_transform(column_to_normalize2)\n",
    "standardized_column3 = scaler.fit_transform(column_to_normalize3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a986a90-f8ac-4fe1-8282-27760f2b237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_context[:, 0] = standardized_column1.flatten()\n",
    "X_context[:, 1] = standardized_column2.flatten()\n",
    "X_context[:, 2] = standardized_column3.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "252dfa3c-5c16-40e2-8fa0-9fa49ef5cf5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.53660388, -1.34478586, -0.95033935,  1.        ,  0.        ,\n",
       "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_context[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39c47357-3f25-4449-9396-b93405559a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = scaler.fit_transform(y.reshape(-1,1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1843865f-c344-441e-8eb1-c227a266cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb2369d8-e6c9-4f11-8ae7-bdb5777158ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq_train, X_seq_test, X_context_train, X_context_test, y_train, y_test = train_test_split(X_seq, X_context, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60bcd788-106b-42c4-bbdc-525db4371746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21ffb56e-34a1-4971-bde0-5fed984ab7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1EmbedDataset(Dataset):\n",
    "    def __init__(self, X_seq, X_context, y):\n",
    "        self.X_seq = torch.tensor(X_seq, dtype=torch.float32)\n",
    "        self.X_context = torch.tensor(X_context, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_seq[idx], self.X_context[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8e9411f-b234-4cdf-ab12-b635b0f39078",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = F1EmbedDataset(X_seq_train, X_context_train, y_train)\n",
    "test_dataset = F1EmbedDataset(X_seq_test, X_context_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5161cace-8b22-41e0-b331-fdb035e59eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "855b1a12-bf26-49d3-97a8-46cbf4ac639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn  \n",
    "import torch.optim as optim  \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8235898-46af-4c65-9991-ad6d7c2d142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "     \n",
    "        # Initialize positional encoding matrix\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "     \n",
    "        # Calculate sinusoidal values for each dimension\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "     \n",
    "        # Apply sine to even indices and cosine to odd indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "     \n",
    "        # Add batch dimension\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Add positional encoding to embeddings\n",
    "        x = x + self.pe[:, :x.size(1)].to(x.device)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cdf78df-d631-4825-8860-c003ad251b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Embedder(nn.Module):\n",
    "    def __init__(self, telemetry_dim, context_dim, d_model=512, nhead=4, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Linear(telemetry_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.context_mlp = nn.Sequential(\n",
    "            nn.Linear(context_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, d_model)\n",
    "        )\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(d_model * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_seq, x_context):\n",
    "        x_seq = self.embedding_layer(x_seq)\n",
    "        x_seq = self.pos_encoder(x_seq)\n",
    "        z_seq = self.transformer(x_seq)\n",
    "        z_seq = z_seq.mean(dim=1)\n",
    "\n",
    "        z_context = self.context_mlp(x_context)\n",
    "\n",
    "        combined = torch.cat([z_seq, z_context], dim=1)\n",
    "        output = self.regressor(combined)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65151ad3-f994-4afa-a631-17cfd66297dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = F1Embedder(\n",
    "    telemetry_dim=X_seq.shape[2],\n",
    "    context_dim=X_context.shape[1],\n",
    "    d_model=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b58415b0-dd58-49b4-b903-e86caea83908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1416 1416 354\n"
     ]
    }
   ],
   "source": [
    "print(len(X_seq_train), len(X_context_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "059d4cec-c780-47dd-b630-fdbf4baadbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1d74e75-42c1-4db8-8377-17358d69e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce1d15f3-4d2b-443d-a903-a4901a52ce64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F1Embedder(\n",
       "  (embedding_layer): Linear(in_features=6, out_features=64, bias=True)\n",
       "  (pos_encoder): PositionalEncoding()\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (context_mlp): Sequential(\n",
       "    (0): Linear(in_features=22, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (regressor): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e197cc32-b8ed-4b6d-9849-5ff9eadd9222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:12<00:00,  3.56it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "for X_seq, X_context, y in tqdm(train_loader, desc=\"training\"):\n",
    "    X_seq = X_seq.to(device)\n",
    "    X_context = X_context.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred = model(X_seq, X_context)       # Forward pass\n",
    "    loss = criterion(pred, y)            # Compute loss\n",
    "\n",
    "    loss.backward()                      # Backward pass\n",
    "    optimizer.step()                     # Update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dac45e1-a701-4a0a-92e9-b06d6077983b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F1Embedder(\n",
       "  (embedding_layer): Linear(in_features=6, out_features=64, bias=True)\n",
       "  (pos_encoder): PositionalEncoding()\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (context_mlp): Sequential(\n",
       "    (0): Linear(in_features=22, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (regressor): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db4e0545-5860-4ccb-a794-4ea5a8dab09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_seq, X_context, y in test_loader:\n",
    "        X_seq = X_seq.to(device)\n",
    "        X_context = X_context.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        preds = model(X_seq, X_context)\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_targets.append(y.cpu())\n",
    "\n",
    "# Stack all batches into single arrays\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_targets = torch.cat(all_targets).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49eba4bb-ee74-4412-92a9-f9486b2fce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_orig = scaler.inverse_transform(all_preds.reshape(-1, 1))\n",
    "y_test_orig = scaler.inverse_transform(all_targets.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebe889dd-71c5-442f-b55f-c04c2afd3493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 14.8579\n",
      "Test MAE: 2.7879\n",
      "R2 Score: 0.8235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def mean_squared_error(a, b):\n",
    "    mse = np.mean(np.square(a - b))\n",
    "    return mse\n",
    "    \n",
    "mse = mean_squared_error(y_test_orig, y_pred_orig)\n",
    "mae = mean_absolute_error(y_test_orig, y_pred_orig)\n",
    "r2 = r2_score(y_test_orig, y_pred_orig)\n",
    "\n",
    "print(f\"Test MSE: {mse:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5d270a2-6e33-4ecf-b93f-67a837957aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'f1-embed-model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
